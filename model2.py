# -*- coding: utf-8 -*-
"""Untitled0.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1rHMmC49oT04lElk08hSPB8G9n7G2J2mg
"""

import pandas as pd
import numpy as np 
import matplotlib.pyplot as plt 
import seaborn as sns
import random
from sklearn.model_selection import train_test_split
import tensorflow as tf
from tensorflow.keras import datasets, models,layers
import keras
from keras.models import Sequential
from keras.layers import Conv2D, MaxPooling2D, InputLayer,Flatten,Dense
import matplotlib.pyplot as plt
import tensorboard
from keras.applications.vgg16 import VGG16
from keras.callbacks import TensorBoard
import keras
import cv2
from skimage.transform import resize
from skimage.io import imread
from sklearn.model_selection import train_test_split
import numpy as np
import os
from random import shuffle
from tqdm import tqdm
from tensorflow.python.framework import ops

x_train = np.load('/content/drive/MyDrive/x_train.npy')
y_train = np.load('/content/drive/MyDrive/y_train.npy')
x_test = np.load('/content/drive/MyDrive/x_test.npy')
y_test = np.load('/content/drive/MyDrive/y_test.npy')
print(x_train.shape)

pip install tflearn

import tflearn
from tflearn.layers.conv import conv_2d, max_pool_2d 
from tflearn.layers.core import input_data, dropout, fully_connected , flatten
from tflearn.layers.estimator import regression 

conv = input_data(shape=[None, 150, 150, 1], name='input')
conv = conv_2d(conv, 64, 5, activation='relu')
conv = max_pool_2d(conv, 5)

conv = conv_2d(conv, 512, 5, activation='relu')
conv = max_pool_2d(conv, 5)

conv = conv_2d(conv, 1024, 6, activation='relu')
conv = max_pool_2d(conv, 6)

conv = conv_2d(conv, 2048, 7, activation='relu')
conv = max_pool_2d(conv, 7)

conv = conv_2d(conv, 1024, 6, activation='relu')
conv = max_pool_2d(conv, 6)

conv = conv_2d(conv, 512, 5, activation='relu')
conv = max_pool_2d(conv, 5)

conv = conv_2d(conv, 64, 5, activation='relu')
conv = max_pool_2d(conv, 5)

conv = flatten(conv)
conv = fully_connected(conv, 32, activation='relu')
conv = fully_connected(conv, 2, activation='softmax')

conv = regression(conv, optimizer ='adam', learning_rate = 1e-3,
      loss ='categorical_crossentropy', name ='targets')

model = tflearn.DNN(conv, tensorboard_dir='/content/drive/MyDrive/log1', tensorboard_verbose=3)

model.fit({'input': x_train},
          {'targets': y_train},
          n_epoch=15,
          validation_set=({'input': x_test}, {'targets': y_test}),
          show_metric=True,
          snapshot_step=500, run_id='detect_autism')
model.save('/content/drive/MyDrive/mohamed1.h5')

import csv

model.load('/content/drive/MyDrive/./mohamed1.h5')
testPath = '/content/drive/MyDrive/test/test/'
test = []
for imgName in os.listdir(testPath):
    path = os.path.join(testPath, imgName)
    image = imread(path, True)
    image = np.array(resize(image, (150, 150)))
    image = image.reshape(1,150,150,1)
    prediction = model.predict(image)[0]
    print(prediction)
    
    if prediction[0] > prediction[1]:
        test.append([imgName,1])
    else:
        test.append([imgName,0])

test = np.array(test)
print(test)

for i in test:
  with open('/content/drive/MyDrive/Submit.csv', mode='a') as IMG:
    IMG_ = csv.writer(IMG, delimiter=',', quotechar='"', quoting=csv.QUOTE_MINIMAL)
    IMG_.writerow(i)

